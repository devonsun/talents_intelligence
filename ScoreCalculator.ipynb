{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ScoreCalculator.py\n",
    "# read pdf into text\n",
    "from __future__ import division\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import ntpath\n",
    "import pprint\n",
    "import operator\n",
    "from docx import Document\n",
    "from Utils import get_keywords, split_text_to_tokens\n",
    "import nltk\n",
    "path = '/Users/ashleyzhao/Desktop/talents.ai/SampleResumes'\n",
    "scores = {}\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "def write_sorted_scores_to_csv(sorted_scores):\n",
    "    with open('scores.csv', 'w') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        csv_writer.writerow(['filename', 'total score', 'phd score', 'computer score', 'math score', 'experience score'])\n",
    "        for line in sorted_scores:\n",
    "            csv_writer.writerow([line[0], line[1][0], line[1][1], line[1][2], line[1][3], line[1][4]])\n",
    "\n",
    "\n",
    "def get_computer_keywords():\n",
    "    return get_keywords('./keywords/computer.txt')\n",
    "\n",
    "\n",
    "def get_math_keywords():\n",
    "    return get_keywords('./keywords/math.txt')\n",
    "\n",
    "\n",
    "def get_experience_keywords():\n",
    "    return get_keywords('./keywords/experience.txt')\n",
    "\n",
    "\n",
    "\n",
    "def cal_score_from_words(tokens, c_keywords, m_keywords, e_keywords, phd_keywords):\n",
    "    alpha = 0.5 #weight for Computer\n",
    "    beta = 0.3 #weight for Math\n",
    "    gamma = 0.2 #weight for Experience\n",
    "    e = random.choice([0.2,0])  #residual\n",
    "    phd_keywords_set, c_keywords_set, m_keywords_set, e_keywords_set = set(), set(), set(), set()\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in phd_keywords: #if degree is Ph.D\n",
    "            phd_keywords_set.add(token)\n",
    "            D = 5\n",
    "        else:\n",
    "            D = 0\n",
    "            if token in c_keywords:\n",
    "                c_keywords_set.add(token)\n",
    "            if token in m_keywords:\n",
    "                m_keywords_set.add(token)\n",
    "            if token in e_keywords:\n",
    "                e_keywords_set.add(token)\n",
    "\n",
    "    #print (\"phd: \", str(phd_keywords_set))\n",
    "    #print (\"computer: \", str(c_keywords_set))\n",
    "    #print (\"math: \", str(m_keywords_set))\n",
    "    #print (\"experience: \", str(e_keywords_set))\n",
    "    # Y = 1 + alpha*C + beta*M + gamma*E + D + e # Score of the resume\n",
    "    D = 3\n",
    "    Y = 1 + alpha * len(c_keywords_set) + beta * len(m_keywords_set) + gamma * len(e_keywords_set) + D * len(phd_keywords_set)\n",
    "    return (round(Y,2), 100 * len(phd_keywords_set) / len(phd_keywords), 100 * len(c_keywords_set)/ len(c_keywords),\n",
    "            100 * len(m_keywords_set) / len(m_keywords), 100 * len(e_keywords_set) / len(e_keywords))\n",
    "\n",
    "#convert docx to txt\n",
    "def document_to_text(filename):\n",
    "    document = Document(filename)\n",
    "    paratextlist = []\n",
    "    for paragraph in document.paragraphs:\n",
    "        paratextlist.append(paragraph.text)\n",
    "    return '\\n'.join(paratextlist)\n",
    "    \n",
    "#wrapper for parsing both pdf and docx to tokens\n",
    "def get_tokens(filename):\n",
    "    all_tokens = []\n",
    "    if filename.endswith(\"pdf\"):\n",
    "        all_tokens = split_text_to_tokens(filename)\n",
    "    else:\n",
    "        tokens = (document_to_text(filename)).lower().split()\n",
    "        bigrams = [bigram[0] + ' ' + bigram[1] for bigram in nltk.bigrams(tokens)]\n",
    "        trigrams = [trigram[0] + ' ' + trigram[1] + ' ' + trigram[2] for trigram in nltk.trigrams(tokens)]\n",
    "        all_tokens = tokens + bigrams + trigrams\n",
    "    return all_tokens\n",
    "\n",
    "def get_score(filename, c_keywords, m_keywords, e_keywords, phd_keywords):\n",
    "    tokens = get_tokens(filename)\n",
    "    return cal_score_from_words(tokens, c_keywords, m_keywords, e_keywords, phd_keywords)\n",
    "\n",
    "\n",
    "def cal_scores_of_all_files():\n",
    "    #computer science keywords\n",
    "    c_keywords = get_computer_keywords()\n",
    "\n",
    "    #math keywords\n",
    "    m_keywords = get_math_keywords()\n",
    "    #degree\n",
    "    phd_keywords = ['phd','ph.d','doctor']\n",
    "\n",
    "    #experience keywords\n",
    "    e_keywords = get_experience_keywords()\n",
    "    \n",
    "    all_resumes = glob.glob(os.path.join(path, '*.pdf')) + glob.glob(os.path.join(path, '*.docx'))\n",
    "    for filename in all_resumes:\n",
    "        scores[ntpath.basename(filename)] = get_score(filename, c_keywords, m_keywords, e_keywords, phd_keywords)\n",
    "        \n",
    "        \n",
    "    #scores is a dictionary of {'filename': (score, p_score, c_score, m_score, e_score)}\n",
    "    #sorted_scores is a list sorted by highest score first\n",
    "    sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    write_sorted_scores_to_csv(sorted_scores)\n",
    "    print(\"resumes: \",len(sorted_scores))\n",
    "    pp.pprint(sorted_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/ashleyzhao.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-657-resume_xichen.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-658-sue_bose.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-659-zhaohuiguo_resume.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-661-yinqi_tang_resume.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-662-arvind_surve.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-663-data_scientist_2017.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-664-vibhor_mehta11.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-665-skanda_narendrabhargav.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-667-henry_hu_resume.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-668-resume0306.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-669-weizhi_zhang_cmu_latest_software_engineering_intern_summer_2017.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-670-ericbairesume.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/entry-671-tmp_32282resume_dan_burke794345727.pdf\n",
      "/Users/ashleyzhao/Desktop/talents.ai/SampleResumes/oldashley_resume.pdf\n",
      "resumes:  28\n",
      "[   (   'entry-659-zhaohuiguo_resume.pdf',\n",
      "        (   14.4,\n",
      "            33.333333333333336,\n",
      "            23.529411764705884,\n",
      "            12.244897959183673,\n",
      "            8.823529411764707)),\n",
      "    (   'entry-657-resume_xichen.pdf',\n",
      "        (11.8, 0.0, 22.058823529411764, 22.448979591836736, 0.0)),\n",
      "    (   'entry-668-resume0306.pdf',\n",
      "        (10.7, 0.0, 26.470588235294116, 2.0408163265306123, 5.882352941176471)),\n",
      "    (   'entry-658-sue_bose.pdf',\n",
      "        (   9.9,\n",
      "            33.333333333333336,\n",
      "            7.352941176470588,\n",
      "            20.408163265306122,\n",
      "            5.882352941176471)),\n",
      "    (   'entry-663-data_scientist_2017.pdf',\n",
      "        (8.5, 0.0, 19.11764705882353, 4.081632653061225, 5.882352941176471)),\n",
      "    ('ashleyzhao.pdf', (8.5, 0.0, 17.647058823529413, 10.204081632653061, 0.0)),\n",
      "    (   'entry-665-skanda_narendrabhargav.pdf',\n",
      "        (8.2, 0.0, 19.11764705882353, 2.0408163265306123, 5.882352941176471)),\n",
      "    (   'entry-26-n_v_yadav_dokkuresume_.docx',\n",
      "        (8.2, 0.0, 16.176470588235293, 10.204081632653061, 2.9411764705882355)),\n",
      "    (   'entry-145-resume_ralic_20170203.docx',\n",
      "        (7.6, 0.0, 13.235294117647058, 10.204081632653061, 8.823529411764707)),\n",
      "    (   'entry-128-himajavadagads.docx',\n",
      "        (7.1, 0.0, 11.764705882352942, 10.204081632653061, 8.823529411764707)),\n",
      "    (   'entry-670-ericbairesume.pdf',\n",
      "        (6.9, 0.0, 13.235294117647058, 8.16326530612245, 2.9411764705882355)),\n",
      "    (   'entry-664-vibhor_mehta11.pdf',\n",
      "        (6.9, 0.0, 8.823529411764707, 14.285714285714286, 11.764705882352942)),\n",
      "    (   'entry-662-arvind_surve.pdf',\n",
      "        (6.5, 0.0, 14.705882352941176, 2.0408163265306123, 2.9411764705882355)),\n",
      "    (   'entry-118-aksoydemet.docx',\n",
      "        (6.3, 0.0, 13.235294117647058, 0.0, 11.764705882352942)),\n",
      "    (   'entry-669-weizhi_zhang_cmu_latest_software_engineering_intern_summer_2017.pdf',\n",
      "        (5.8, 0.0, 11.764705882352942, 4.081632653061225, 2.9411764705882355)),\n",
      "    (   'oldashley_resume.pdf',\n",
      "        (5.6, 0.0, 11.764705882352942, 4.081632653061225, 0.0)),\n",
      "    (   'entry-661-yinqi_tang_resume.pdf',\n",
      "        (4.5, 0.0, 10.294117647058824, 0.0, 0.0)),\n",
      "    (   'entry-125-resume_deepa_goya_sanfran_2016.docx',\n",
      "        (4.0, 0.0, 4.411764705882353, 6.122448979591836, 8.823529411764707)),\n",
      "    (   'entry-150-shilpasrinivasan2016_new__copy.docx',\n",
      "        (3.7, 0.0, 5.882352941176471, 2.0408163265306123, 5.882352941176471)),\n",
      "    (   'entry-25-resume_20160118.docx',\n",
      "        (3.7, 0.0, 2.9411764705882355, 10.204081632653061, 2.9411764705882355)),\n",
      "    (   'entry-41-jothiswaran_sivakumar_on_update.docx',\n",
      "        (3.5, 0.0, 5.882352941176471, 2.0408163265306123, 2.9411764705882355)),\n",
      "    (   'entry-122-grace_hu_resume_thanks.docx',\n",
      "        (2.8, 0.0, 4.411764705882353, 2.0408163265306123, 0.0)),\n",
      "    (   'entry-58-yirong.song_resume.docx',\n",
      "        (2.8, 0.0, 4.411764705882353, 2.0408163265306123, 0.0)),\n",
      "    (   'entry-667-henry_hu_resume.pdf',\n",
      "        (2.5, 0.0, 2.9411764705882355, 2.0408163265306123, 2.9411764705882355)),\n",
      "    (   'entry-18-christopher_hohman_resume_1_18_17.docx',\n",
      "        (2.1, 0.0, 1.4705882352941178, 0.0, 8.823529411764707)),\n",
      "    (   'entry-126-data_analyst_resume_4_jacob_vasquez_cabral.docx',\n",
      "        (1.3, 0.0, 0.0, 2.0408163265306123, 0.0)),\n",
      "    (   'entry-671-tmp_32282resume_dan_burke794345727.pdf',\n",
      "        (1.2, 0.0, 0.0, 0.0, 2.9411764705882355)),\n",
      "    ('entry-152-resume__ivy_zhang.docx', (1.0, 0.0, 0.0, 0.0, 0.0))]\n"
     ]
    }
   ],
   "source": [
    "cal_scores_of_all_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cfda11b7534c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_text_to_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'docx'"
     ]
    }
   ],
   "source": [
    "# %load ScoreCalculator.py\n",
    "# read pdf into text\n",
    "from __future__ import division\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import ntpath\n",
    "import pprint\n",
    "import operator\n",
    "from docx import Document\n",
    "from Utils import get_keywords, split_text_to_tokens\n",
    "import nltk\n",
    "path = '/Users/devonsun/Dropbox/DSJF_Sofia'\n",
    "scores = {}\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "def write_sorted_scores_to_csv(sorted_scores):\n",
    "    with open('scores.csv', 'w') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        csv_writer.writerow(['filename', 'total score', 'phd score', 'computer score', 'math score', 'experience score'])\n",
    "        for line in sorted_scores:\n",
    "            csv_writer.writerow([line[0], line[1][0], line[1][1], line[1][2], line[1][3], line[1][4]])\n",
    "\n",
    "\n",
    "def get_computer_keywords():\n",
    "    return get_keywords('./keywords/computer.txt')\n",
    "\n",
    "\n",
    "def get_math_keywords():\n",
    "    return get_keywords('./keywords/math.txt')\n",
    "\n",
    "\n",
    "def get_experience_keywords():\n",
    "    return get_keywords('./keywords/experience.txt')\n",
    "\n",
    "\n",
    "\n",
    "def cal_score_from_words(tokens, c_keywords, m_keywords, e_keywords, phd_keywords):\n",
    "    alpha = 0.5 #weight for Computer\n",
    "    beta = 0.3 #weight for Math\n",
    "    gamma = 0.2 #weight for Experience\n",
    "    e = random.choice([0.2,0])  #residual\n",
    "    phd_keywords_set, c_keywords_set, m_keywords_set, e_keywords_set = set(), set(), set(), set()\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in phd_keywords: #if degree is Ph.D\n",
    "            phd_keywords_set.add(token)\n",
    "            D = 5\n",
    "        else:\n",
    "            D = 0\n",
    "            if token in c_keywords:\n",
    "                c_keywords_set.add(token)\n",
    "            if token in m_keywords:\n",
    "                m_keywords_set.add(token)\n",
    "            if token in e_keywords:\n",
    "                e_keywords_set.add(token)\n",
    "\n",
    "    #print (\"phd: \", str(phd_keywords_set))\n",
    "    #print (\"computer: \", str(c_keywords_set))\n",
    "    #print (\"math: \", str(m_keywords_set))\n",
    "    #print (\"experience: \", str(e_keywords_set))\n",
    "    # Y = 1 + alpha*C + beta*M + gamma*E + D + e # Score of the resume\n",
    "    D = 3\n",
    "    Y = 1 + alpha * len(c_keywords_set) + beta * len(m_keywords_set) + gamma * len(e_keywords_set) + D * len(phd_keywords_set)\n",
    "    return (round(Y,2), 100 * len(phd_keywords_set) / len(phd_keywords), 100 * len(c_keywords_set)/ len(c_keywords),\n",
    "            100 * len(m_keywords_set) / len(m_keywords), 100 * len(e_keywords_set) / len(e_keywords))\n",
    "\n",
    "#convert docx to txt\n",
    "def document_to_text(filename):\n",
    "    document = Document(filename)\n",
    "    paratextlist = []\n",
    "    for paragraph in document.paragraphs:\n",
    "        paratextlist.append(paragraph.text)\n",
    "    return '\\n'.join(paratextlist)\n",
    "    \n",
    "#wrapper for parsing both pdf and docx to tokens\n",
    "def get_tokens(filename):\n",
    "    all_tokens = []\n",
    "    if filename.endswith(\"pdf\"):\n",
    "        all_tokens = split_text_to_tokens(filename)\n",
    "    else:\n",
    "        tokens = (document_to_text(filename)).lower().split()\n",
    "        bigrams = [bigram[0] + ' ' + bigram[1] for bigram in nltk.bigrams(tokens)]\n",
    "        trigrams = [trigram[0] + ' ' + trigram[1] + ' ' + trigram[2] for trigram in nltk.trigrams(tokens)]\n",
    "        all_tokens = tokens + bigrams + trigrams\n",
    "    return all_tokens\n",
    "\n",
    "def get_score(filename, c_keywords, m_keywords, e_keywords, phd_keywords):\n",
    "    tokens = get_tokens(filename)\n",
    "    return cal_score_from_words(tokens, c_keywords, m_keywords, e_keywords, phd_keywords)\n",
    "\n",
    "\n",
    "def cal_scores_of_all_files():\n",
    "    #computer science keywords\n",
    "    c_keywords = get_computer_keywords()\n",
    "\n",
    "    #math keywords\n",
    "    m_keywords = get_math_keywords()\n",
    "    #degree\n",
    "    phd_keywords = ['phd','ph.d','doctor']\n",
    "\n",
    "    #experience keywords\n",
    "    e_keywords = get_experience_keywords()\n",
    "    \n",
    "    all_resumes = glob.glob(os.path.join(path, '*.pdf')) + glob.glob(os.path.join(path, '*.docx'))\n",
    "    for filename in all_resumes:\n",
    "        scores[ntpath.basename(filename)] = get_score(filename, c_keywords, m_keywords, e_keywords, phd_keywords)\n",
    "        \n",
    "        \n",
    "    #scores is a dictionary of {'filename': (score, p_score, c_score, m_score, e_score)}\n",
    "    #sorted_scores is a list sorted by highest score first\n",
    "    sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    write_sorted_scores_to_csv(sorted_scores)\n",
    "    print(\"resumes: \",len(sorted_scores))\n",
    "    pp.pprint(sorted_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal_scores_of_all_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
